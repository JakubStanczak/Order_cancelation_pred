{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scikitplot as skplt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, cross_val_score, cross_val_predict\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from functools import partial\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1067371 entries, 12 to 541893\n",
      "Data columns (total 11 columns):\n",
      "invoice         1067371 non-null int32\n",
      "stock_code      1067371 non-null int16\n",
      "description     1062989 non-null object\n",
      "quantity        1067371 non-null int32\n",
      "invoice_date    1067371 non-null datetime64[ns]\n",
      "price_unit      1067371 non-null float16\n",
      "price_total     1067371 non-null float32\n",
      "customer_id     1067371 non-null int16\n",
      "country         1067371 non-null object\n",
      "is_canceled     520142 non-null object\n",
      "is_test         1067371 non-null bool\n",
      "dtypes: bool(1), datetime64[ns](1), float16(1), float32(1), int16(2), int32(2), object(3)\n",
      "memory usage: 60.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_hdf('../../module3/input/train_online_retail.h5')\n",
    "test = pd.read_hdf('../../module3/input/test_online_retail.h5')\n",
    "df_all = pd.concat([train, test], sort=False)\n",
    "del train, test\n",
    "gc.collect()\n",
    "\n",
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_all[ ~df_all['is_canceled'].isnull()]\n",
    "description_canc = train.groupby(['stock_code', 'description'])['is_canceled'].agg(np.sum).reset_index()\n",
    "description_canc['is_canceled'] = description_canc['is_canceled'].astype(int)\n",
    "description_canc['description'] = description_canc['description'].map(lambda x: str(x).strip())\n",
    "description_canc['words'] = description_canc['description'].map(lambda x: x.split(' '))\n",
    "\n",
    "most_canceled_words = {}\n",
    "for i in range(description_canc.shape[0]):\n",
    "    word_lst = description_canc['words'].iloc[i]    \n",
    "    for word in word_lst:\n",
    "        curr_num = most_canceled_words.get(word, 0)\n",
    "        \n",
    "        most_canceled_words[word] = curr_num + description_canc['is_canceled'].iloc[i]\n",
    "\n",
    "#sorted(most_canceled_words.items() ,  key=lambda x: x[1], reverse=True)\n",
    "\n",
    "words_to_del = []\n",
    "for word in most_canceled_words.keys():\n",
    "    if len(word) <= 2:\n",
    "        words_to_del.append(word)\n",
    "for word in words_to_del:\n",
    "    del most_canceled_words[word]\n",
    "    \n",
    "most_canceled_words = defaultdict(lambda: 0, most_canceled_words)\n",
    "\n",
    "stock_code_word_score = {}\n",
    "for i in range(description_canc.shape[0]):\n",
    "    word_lst = description_canc['words'].iloc[i]\n",
    "    stock_score = 0\n",
    "    for word in word_lst:\n",
    "        stock_score += most_canceled_words[word]\n",
    "        \n",
    "    stock_code_word_score[description_canc['stock_code'].iloc[i]] = stock_score\n",
    "    \n",
    "stock_code_word_score = defaultdict(lambda: 0, stock_code_word_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_to_dict(group_key, agg_func):\n",
    "    print(type(group_key))\n",
    "    train = df_all[ ~df_all['is_canceled'].isnull()]\n",
    "    dict_ = train.groupby(group_key)['is_canceled'].agg(agg_func).to_dict()\n",
    "    if -1 in dict_: del dict_[-1]\n",
    "    \n",
    "    if type(group_key) == list:\n",
    "        keys_to_del = []\n",
    "        for key in dict_.keys():\n",
    "            if -1 in key:\n",
    "                keys_to_del.append(key)\n",
    "        for key in keys_to_del:\n",
    "            del dict_[key]\n",
    "    else:\n",
    "        if -1 in dict_: del dict_[-1]\n",
    "    \n",
    "    mean = np.mean( list(dict_.values()) )\n",
    "    return defaultdict(lambda: mean, dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_to_dict(group_key, agg_func):\n",
    "    train = df_all[ ~df_all['is_canceled'].isnull()]\n",
    "    dict_ = train.groupby(group_key)['is_canceled'].agg(agg_func).to_dict()\n",
    "    if -1 in dict_: del dict_[-1]\n",
    "        \n",
    "    mean = np.mean( list(dict_.values()) )\n",
    "    return defaultdict(lambda: mean, dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_cnt_customer_orders = group_to_dict('customer_id', agg_func=np.size)\n",
    "dict_cnt_customer_cancel = group_to_dict('customer_id', agg_func=np.sum)\n",
    "dict_cnt_product_orders = group_to_dict('stock_code', agg_func=np.size)\n",
    "dict_cnt_product_cancel = group_to_dict('stock_code', agg_func=np.sum)\n",
    "dict_cnt_customer_produckt_orders = group_to_dict(['customer_id','stock_code'], np.size)\n",
    "dict_cnt_customer_produckt_cancel = group_to_dict(['customer_id','stock_code'], np.sum)\n",
    "\n",
    "# customer feats\n",
    "df_all['cnt_customer_orders'] = df_all['customer_id'].map(dict_cnt_customer_orders)\n",
    "df_all['cnt_customer_cancel'] = df_all['customer_id'].map(dict_cnt_customer_cancel)\n",
    "df_all['prc_customer_cancel'] = df_all[['cnt_customer_orders', 'cnt_customer_cancel']].apply(lambda x: x['cnt_customer_cancel'] / x['cnt_customer_orders'] if x['cnt_customer_orders'] != 0 else 0, axis=1)\n",
    "\n",
    "# produkt feats\n",
    "df_all['cnt_product_orders'] = df_all['stock_code'].map(dict_cnt_product_orders)\n",
    "df_all['cnt_product_cancel'] = df_all['stock_code'].map(dict_cnt_product_cancel)\n",
    "df_all['prc_product_cancel'] = df_all[['cnt_product_orders', 'cnt_product_cancel']].apply(lambda x: x['cnt_product_cancel'] / x['cnt_product_orders'] if x['cnt_product_orders'] != 0 else 0, axis=1)\n",
    "\n",
    "# produckt per customer feats\n",
    "# df_all['cnt_customer_produckt_orders'] = df_all['stock_code'].map(dict_cnt_product_orders)\n",
    "# df_all['cnt_customer_produckt_cancel'] = df_all['stock_code'].map(dict_cnt_product_cancel)\n",
    "\n",
    "# describsion feats\n",
    "# df_all['stock_word_score'] = df_all['stock_code'].map(stock_code_word_score)\n",
    "\n",
    "# date feats\n",
    "df_all['invoice_year'] = df_all['invoice_date'].dt.year\n",
    "df_all['invoice_month'] = df_all['invoice_date'].dt.month\n",
    "df_all['invoice_day_of_m'] = df_all['invoice_date'].dt.day\n",
    "df_all['invoice_day_of_y'] = df_all['invoice_date'].dt.dayofyear\n",
    "df_all['invoice_hour'] = df_all['invoice_date'].dt.hour\n",
    "\n",
    "# category feats\n",
    "df_all['country__cat'] = pd.factorize(df_all['country'])[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feats_X_y(df):\n",
    "    \n",
    "    # select feats\n",
    "    black_list = ['is_canceled', 'is_test', 'total_return', 'is_canceled_pred', 'total_return', 'total_return_pred', 'predict_proba', 'mse']\n",
    "    feats = df.select_dtypes([np.bool, np.number]).columns\n",
    "    feats = [x for x in feats if x not in black_list]\n",
    "\n",
    "    feats = [x for x in feats if x + '_log' not in df.columns]\n",
    "                  \n",
    "    X = df[feats].values\n",
    "    y = df['is_canceled'].values\n",
    "    \n",
    "    return X, y, feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, scoring='f1', check_distribution=False):\n",
    "    cv = StratifiedKFold(n_splits=3, random_state=0, shuffle=True)\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring=scoring)\n",
    "    print('scores: {}'.format(scores))\n",
    "    print('mean: {}, std: {} \\n'.format(np.mean(scores), np.std(scores)))\n",
    "    \n",
    "    if check_distribution:\n",
    "        y_pred = pd.Series(cross_val_predict(model, X, y, cv=cv))\n",
    "        print('y_pred value_counts: \\n{}'.format(y_pred.value_counts(normalize=True)))\n",
    "\n",
    "        \n",
    "        \n",
    "def plot_model_char(model, check_confusion=True, check_feature_importance=True, check_learning_curve=True):\n",
    "    \n",
    "    if check_confusion:\n",
    "        cv = StratifiedKFold(n_splits=3, random_state=0, shuffle=True)\n",
    "        y_pred = cross_val_predict(model, X, y, cv=cv)\n",
    "        skplt.metrics.plot_confusion_matrix(y, y_pred, normalize=True, figsize=(10 ,10))\n",
    "    \n",
    "    if check_feature_importance or check_learning_curve:\n",
    "        model.fit(X, y)\n",
    "    \n",
    "    if check_feature_importance:\n",
    "        skplt.estimators.plot_feature_importances(model, feature_names=feats, x_tick_rotation=90, figsize=(15, 5))\n",
    "    \n",
    "    if check_learning_curve:\n",
    "        skplt.estimators.plot_learning_curve(model, X, y, figsize=(15, 5), cv=3, scoring='recall');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare to train\n",
    "train = df_all[ ~df_all['is_test'] ].copy()\n",
    "test = df_all[ df_all['is_test'] ].copy()\n",
    "\n",
    "#release memory\n",
    "del df_all\n",
    "gc.collect()\n",
    "\n",
    "train['cnt_product_cancel'] = train['cnt_product_cancel'].astype(float)\n",
    "train['cnt_customer_cancel'] = train['cnt_customer_cancel'].astype(float)\n",
    "\n",
    "test['cnt_product_cancel'] = test['cnt_product_cancel'].astype(float)\n",
    "test['cnt_customer_cancel'] = test['cnt_customer_cancel'].astype(float)\n",
    "\n",
    "train['is_canceled'] = train['is_canceled'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 520142 entries, 12 to 541909\n",
      "Data columns (total 24 columns):\n",
      "invoice                520142 non-null int32\n",
      "stock_code             520142 non-null int16\n",
      "description            517903 non-null object\n",
      "quantity               520142 non-null int32\n",
      "invoice_date           520142 non-null datetime64[ns]\n",
      "price_unit             520142 non-null float16\n",
      "price_total            520142 non-null float32\n",
      "customer_id            520142 non-null int16\n",
      "country                520142 non-null object\n",
      "is_canceled            520142 non-null bool\n",
      "is_test                520142 non-null bool\n",
      "cnt_customer_orders    520142 non-null float64\n",
      "cnt_customer_cancel    520142 non-null float64\n",
      "prc_customer_cancel    520142 non-null float64\n",
      "cnt_product_orders     520142 non-null float64\n",
      "cnt_product_cancel     520142 non-null float64\n",
      "prc_product_cancel     520142 non-null float64\n",
      "stock_word_score       520142 non-null int64\n",
      "invoice_year           520142 non-null int64\n",
      "invoice_month          520142 non-null int64\n",
      "invoice_day_of_m       520142 non-null int64\n",
      "invoice_day_of_y       520142 non-null int64\n",
      "invoice_hour           520142 non-null int64\n",
      "country__cat           520142 non-null int64\n",
      "dtypes: bool(2), datetime64[ns](1), float16(1), float32(1), float64(6), int16(2), int32(2), int64(7), object(2)\n",
      "memory usage: 77.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Order aproach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>invoice</th>\n",
       "      <th>stock_code</th>\n",
       "      <th>description</th>\n",
       "      <th>quantity</th>\n",
       "      <th>invoice_date</th>\n",
       "      <th>price_unit</th>\n",
       "      <th>price_total</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>country</th>\n",
       "      <th>is_canceled</th>\n",
       "      <th>...</th>\n",
       "      <th>cnt_product_orders</th>\n",
       "      <th>cnt_product_cancel</th>\n",
       "      <th>prc_product_cancel</th>\n",
       "      <th>stock_word_score</th>\n",
       "      <th>invoice_year</th>\n",
       "      <th>invoice_month</th>\n",
       "      <th>invoice_day_of_m</th>\n",
       "      <th>invoice_day_of_y</th>\n",
       "      <th>invoice_hour</th>\n",
       "      <th>country__cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>DOOR MAT BLACK FLOCK</td>\n",
       "      <td>10</td>\n",
       "      <td>2009-12-01 09:06:00</td>\n",
       "      <td>5.949219</td>\n",
       "      <td>59.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>242.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004132</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>335</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>LOVE BUILDING BLOCK WORD</td>\n",
       "      <td>18</td>\n",
       "      <td>2009-12-01 09:06:00</td>\n",
       "      <td>5.449219</td>\n",
       "      <td>98.099998</td>\n",
       "      <td>1</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>890.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.012360</td>\n",
       "      <td>159</td>\n",
       "      <td>2009</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>335</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>HOME BUILDING BLOCK WORD</td>\n",
       "      <td>3</td>\n",
       "      <td>2009-12-01 09:06:00</td>\n",
       "      <td>5.949219</td>\n",
       "      <td>17.850000</td>\n",
       "      <td>1</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1081.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.010176</td>\n",
       "      <td>183</td>\n",
       "      <td>2009</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>335</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>ASSORTED COLOUR BIRD ORNAMENT</td>\n",
       "      <td>16</td>\n",
       "      <td>2009-12-01 09:06:00</td>\n",
       "      <td>1.690430</td>\n",
       "      <td>27.040001</td>\n",
       "      <td>1</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1384.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.007225</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>335</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>PEACE WOODEN BLOCK LETTERS</td>\n",
       "      <td>3</td>\n",
       "      <td>2009-12-01 09:06:00</td>\n",
       "      <td>6.949219</td>\n",
       "      <td>20.850000</td>\n",
       "      <td>1</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>185.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.016216</td>\n",
       "      <td>243</td>\n",
       "      <td>2009</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>335</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    invoice  stock_code                    description  quantity  \\\n",
       "12        2          12          DOOR MAT BLACK FLOCK         10   \n",
       "13        2          13       LOVE BUILDING BLOCK WORD        18   \n",
       "14        2          14       HOME BUILDING BLOCK WORD         3   \n",
       "15        2          15  ASSORTED COLOUR BIRD ORNAMENT        16   \n",
       "16        2          16     PEACE WOODEN BLOCK LETTERS         3   \n",
       "\n",
       "          invoice_date  price_unit  price_total  customer_id         country  \\\n",
       "12 2009-12-01 09:06:00    5.949219    59.500000            1  United Kingdom   \n",
       "13 2009-12-01 09:06:00    5.449219    98.099998            1  United Kingdom   \n",
       "14 2009-12-01 09:06:00    5.949219    17.850000            1  United Kingdom   \n",
       "15 2009-12-01 09:06:00    1.690430    27.040001            1  United Kingdom   \n",
       "16 2009-12-01 09:06:00    6.949219    20.850000            1  United Kingdom   \n",
       "\n",
       "    is_canceled  ...  cnt_product_orders  cnt_product_cancel  \\\n",
       "12        False  ...               242.0                 1.0   \n",
       "13        False  ...               890.0                11.0   \n",
       "14        False  ...              1081.0                11.0   \n",
       "15        False  ...              1384.0                10.0   \n",
       "16        False  ...               185.0                 3.0   \n",
       "\n",
       "    prc_product_cancel  stock_word_score  invoice_year  invoice_month  \\\n",
       "12            0.004132                 0          2009             12   \n",
       "13            0.012360               159          2009             12   \n",
       "14            0.010176               183          2009             12   \n",
       "15            0.007225                 0          2009             12   \n",
       "16            0.016216               243          2009             12   \n",
       "\n",
       "    invoice_day_of_m  invoice_day_of_y  invoice_hour  country__cat  \n",
       "12                 1               335             9             0  \n",
       "13                 1               335             9             0  \n",
       "14                 1               335             9             0  \n",
       "15                 1               335             9             0  \n",
       "16                 1               335             9             0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def group_orders(df, params_to_group_by, params_to_agg, agg_fun, label_in_df):\n",
    "    orders = df.groupby(params_to_group_by)[params_to_agg].agg(agg_fun).reset_index()\n",
    "    \n",
    "    if label_in_df:\n",
    "        orders['is_canceled'] = orders['is_canceled'].map(lambda x: True if x>0 else False)\n",
    "#         orders['total_return'] = orders['price_total'] * orders['is_canceled']\n",
    "    return orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_group_by = ['invoice', 'customer_id', 'invoice_year', 'invoice_day_of_y', 'invoice_hour', 'country__cat']\n",
    "params_to_sum = ['stock_code', 'price_total', 'is_canceled']\n",
    "params_to_mean = ['cnt_customer_orders',  'cnt_customer_cancel',  'prc_customer_cancel', 'cnt_product_orders', 'cnt_product_cancel', 'prc_product_cancel', 'stock_word_score', 'cnt_customer_produckt_orders', 'cnt_customer_produckt_cancel', 'prc_customer_produckt_cancel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_group_sum = group_orders(train, params_to_group_by, params_to_sum, np.sum, True)\n",
    "train_group_mean = group_orders(train, params_to_group_by, params_to_mean, np.mean, False)\n",
    "test_group_sum = group_orders(test, params_to_group_by, params_to_sum, np.sum, False)\n",
    "test_group_mean = group_orders(test, params_to_group_by, params_to_mean, np.mean, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all agregations into one df\n",
    "train_group = train_group_mean\n",
    "test_group = test_group_mean\n",
    "\n",
    "for param in params_to_sum:\n",
    "    train_group[param] = train_group_sum[param]\n",
    "    if param != 'is_canceled':\n",
    "        test_group[param] = test_group_sum[param]\n",
    "\n",
    "del train_group_sum, train_group_mean, test_group_sum, test_group_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_to_log = ['cnt_customer_orders', 'cnt_customer_cancel', 'cnt_product_orders', 'cnt_product_cancel', 'price_total', 'cnt_customer_produckt_orders', 'cnt_customer_produckt_cancel']\n",
    "\n",
    "for feat in feats_to_log:\n",
    "    if feat in train_group.columns:\n",
    "        train_group[feat + '_log'] = np.log1p(train_group[feat])\n",
    "        if feat != 'total_return':\n",
    "            test_group[feat + '_log'] = np.log1p(test_group[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for feat in train_group.columns:\n",
    "    if 'log' in feat or feat == 'is_canceled': continue\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    train_group[feat].hist(bins=50)\n",
    "    plt.title(feat)\n",
    "    if feat in feats_to_log:\n",
    "        plt.subplot(1,2,2)\n",
    "        np.log1p(train_group[feat]).hist(bins=50)    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, feats = get_feats_X_y(train_group)\n",
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 'learning_rate': 0.05578989271866905, 'max_depth': 14.0\n",
    "#         'colsample_bytree': hp.uniform ('colsample_bytree', 0.8, 1.),\n",
    "#         'subsample': hp.uniform ('subsample', 0.7, 1.),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'max_depth' : 2,\n",
    "    'n_estimators' : 50,\n",
    "    'learning_rate': 0.1,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'subsample': 0.8,  \n",
    "    'seed': 0\n",
    "}\n",
    "model = XGBClassifier(**xgb_params)\n",
    "X, y, feats = get_feats_X_y(train_group)\n",
    "test_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_model_char(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, y, feats = get_feats_X_y(train_group)\n",
    "m = XGBClassifier(**xgb_params)\n",
    "m.fit(X,y)\n",
    "\n",
    "imp = PermutationImportance(m, random_state=0).fit(X,y)\n",
    "eli5.show_weights(imp, feature_names=feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_predict_test(model, df):\n",
    "    cv = StratifiedKFold(n_splits=3, random_state=0, shuffle=True)\n",
    "    return cross_val_predict(model, df[feats], df['is_canceled'], cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_proba_SKFold(df, xgb_params):\n",
    "        X, y, feats = get_feats_X_y(df)\n",
    "        cv = StratifiedKFold(n_splits=3, random_state=0, shuffle=True)\n",
    "        predict_proba = pd.Series([np.nan] * df.shape[0])\n",
    "#         df['predict_proba'] = np.nan\n",
    "        scores = []\n",
    "        for train_idx, test_idx in cv.split(X, y):\n",
    "            model = XGBClassifier(**xgb_params)\n",
    "            model.fit(X[train_idx], y[train_idx])\n",
    "            predict_proba[test_idx] = [x[1] for x in model.predict_proba(X[test_idx])]\n",
    "            \n",
    "        return predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mse on train xgb_params_opt_small  is_canceled_pred total_return total_return_pred\n",
    "treshold = 0.5\n",
    "\n",
    "model = XGBClassifier(**xgb_params)\n",
    "if treshold is None:\n",
    "    train_group['is_canceled_pred'] = fit_and_predict_test(model, train_group)\n",
    "else:\n",
    "    train_group['predict_proba'] = pred_proba_SKFold(train_group, xgb_params)\n",
    "    train_group['is_canceled_pred'] = train_group['predict_proba'].map(lambda x: True if x > treshold else False)\n",
    "    \n",
    "\n",
    "train_group['total_return'] = train_group['price_total'] * train_group['is_canceled']\n",
    "\n",
    "# train_group['total_return_pred'] = train_group['price_total'] * train_group['is_canceled_pred']\n",
    "train_group['total_return_pred'] = train_group['price_total'] * train_group['predict_proba']\n",
    "\n",
    "\n",
    "score = mean_squared_error(train_group['total_return'], train_group['total_return_pred'])\n",
    "print(score)\n",
    "\n",
    "# score by invoice\n",
    "train_group['mse'] = train_group[['total_return', 'total_return_pred']].apply(lambda x: mean_squared_error([x['total_return']], [x['total_return_pred']]), axis=1)\n",
    "\n",
    "# train_group['right_pred'] = train_group[['is_canceled', 'is_canceled_pred']].apply(lambda x: x['is_canceled'] == x['is_canceled_pred'], axis=1)\n",
    "# train_group.groupby('right_pred')['price_total'].agg(np.sum) / train_group.groupby('right_pred')['price_total'].agg(np.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_group[['predict_proba', 'is_canceled_pred', 'mse']].sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 50)\n",
    "train_group.sort_values(by='mse', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperOptf1(train):\n",
    "    X, y, feats = get_feats_X_y(train)\n",
    "\n",
    "\n",
    "    def objective(space):\n",
    "\n",
    "        xgb_params = {\n",
    "            'max_depth': int(space['max_depth']),\n",
    "            'learning_rate': space['learning_rate'],\n",
    "            'colsample_bytree': space['colsample_bytree'],\n",
    "            'subsample': space['subsample'],\n",
    "            'min_child_weight': int(space['min_child_weight']),\n",
    "            'n_estimators': 50,\n",
    "            'objective': 'reg:squarederror',\n",
    "            'seed':0\n",
    "        }\n",
    "        \n",
    "    \n",
    "        predict_proba = pred_proba_SKFold(train_group, xgb_params)\n",
    "        return_pred = train['price_total'] * predict_proba\n",
    "        final_score = mean_squared_error(return_pred, train['total_return'])\n",
    "        \n",
    "        print('final_score: {}'.format(final_score))\n",
    "        return{'loss':final_score, 'status': STATUS_OK }\n",
    "\n",
    "    space ={\n",
    "        'max_depth': hp.quniform ('max_depth', 1, 20, 1),\n",
    "        'colsample_bytree': hp.uniform ('colsample_bytree', 0.8, 1.),\n",
    "        'subsample': hp.uniform ('subsample', 0.7, 1.),\n",
    "        'learning_rate': hp.uniform ('learning_rate', 0.05, 0.3),\n",
    "        'min_child_weight': hp.quniform ('min_child_weight', 1, 10, 1),\n",
    "    }\n",
    "\n",
    "\n",
    "    trials = Trials()\n",
    "    best_params = fmin(fn=objective,\n",
    "                space=space,\n",
    "                algo=partial(tpe.suggest, n_startup_jobs=10),\n",
    "                max_evals=50,\n",
    "                trials=trials)\n",
    "\n",
    "    print(\"The best params: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hyperOptf1(train_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params_opt = {'n_estimators': 50, 'seed':0, 'learning_rate': 0.05068313243959119, 'max_depth': 6, 'min_child_weight': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final predict two models\n",
    "\n",
    "X, y, feats = get_feats_X_y(train_group)\n",
    "\n",
    "model = XGBClassifier(**xgb_params)\n",
    "model.fit(train_group[feats], train_group['is_canceled'])\n",
    "test_group['is_canceled'] = [x[1] for x in model.predict_proba(test_group[feats])]\n",
    "\n",
    "importances = model.feature_importances_\n",
    "for f, i in list(zip(feats, importances)):\n",
    "    print(f,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare submit\n",
    "test_group['total_return'] = test_group['price_total'] * test_group['is_canceled']\n",
    "test_group[ ['invoice', 'total_return'] ].to_csv('../../../output/xgb_and_cnt_features.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
